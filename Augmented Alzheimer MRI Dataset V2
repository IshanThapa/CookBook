{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass #print(os.path.join(dirname, filename))\nprint('Import Complete')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:54:35.869020Z","iopub.execute_input":"2025-08-10T10:54:35.869295Z","iopub.status.idle":"2025-08-10T10:56:02.716887Z","shell.execute_reply.started":"2025-08-10T10:54:35.869274Z","shell.execute_reply":"2025-08-10T10:56:02.715817Z"}},"outputs":[{"name":"stdout","text":"Import Complete\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T11:35:28.721058Z","iopub.execute_input":"2025-08-10T11:35:28.721369Z","iopub.status.idle":"2025-08-10T11:35:46.061054Z","shell.execute_reply.started":"2025-08-10T11:35:28.721341Z","shell.execute_reply":"2025-08-10T11:35:46.060158Z"}},"outputs":[{"name":"stderr","text":"2025-08-10 11:35:30.463147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754825730.675771      72 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754825730.736855      72 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(os.path.join(dirname,))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:59:45.672823Z","iopub.execute_input":"2025-08-10T10:59:45.673150Z","iopub.status.idle":"2025-08-10T10:59:45.678172Z","shell.execute_reply.started":"2025-08-10T10:59:45.673128Z","shell.execute_reply":"2025-08-10T10:59:45.677128Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/augmented-alzheimer-mri-dataset-v2/data/train/MildDemented\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Paths to your training and validation data\ntrain_dir = \"/kaggle/input/augmented-alzheimer-mri-dataset-v2/data/train\"\nval_dir = \"/kaggle/input/augmented-alzheimer-mri-dataset-v2/data/val\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T11:41:49.886220Z","iopub.execute_input":"2025-08-10T11:41:49.886912Z","iopub.status.idle":"2025-08-10T11:41:49.891700Z","shell.execute_reply.started":"2025-08-10T11:41:49.886884Z","shell.execute_reply":"2025-08-10T11:41:49.890726Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"As I can observe in the dataset their are 4 outcomes so I will design a Deep Learning network using keras which has 4 output. I will train 10 Epoch with 10 iteration will use diff type of parameter but 1st will try with __\n\n1.Ek neural net bna rha hu","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths to your training and validation data\ntrain_dir = \"/kaggle/input/augmented-alzheimer-mri-dataset-v2/data/train\"\nval_dir = \"/kaggle/input/augmented-alzheimer-mri-dataset-v2/data/val\"\n\n# Image size and batch size\nIMG_SIZE = (128, 128)\nBATCH_SIZE = 32\n\n# Data augmentation for training set\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\n# Validation set should only be rescaled\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create the data generators\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\"\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\"\n)\n\n# Build the CNN model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(64, (3, 3), activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(128, (3, 3), activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Flatten(),\n    Dense(256, activation=\"relu\"),\n    Dropout(0.5),\n    Dense(4, activation=\"softmax\")  # 4 classes\n])\n\n# Compile the model\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# Summary of model\nmodel.summary()\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=25\n)\n\n# Save the model\nmodel.save(\"alzheimers_classifier.h5\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}